{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "x0lTElJFQKLx",
        "k7atqBQZQe_C",
        "V0QEkm-XRcsP",
        "rECAJNHXSTj_",
        "A3D1zLEWSob1",
        "sYRGduJSSsu6",
        "1pb_ITZ0S3iF",
        "Mnva1dmGS7Y1",
        "uTpdj06oTImo",
        "TAAlbujRTLJx",
        "sjHbGEF1TRqk"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "####import libraries"
      ],
      "metadata": {
        "id": "x0lTElJFQKLx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YrJqJvaLB1bl"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "import pathlib\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Download Dataset"
      ],
      "metadata": {
        "id": "k7atqBQZQe_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
        "data_dir = tf.keras.utils.get_file('flower_photos.tar', origin=dataset_url, extract=True)\n",
        "data_dir = pathlib.Path(data_dir).with_suffix('')"
      ],
      "metadata": {
        "id": "VClgxFORH-N5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_count = len(list(data_dir.glob('*/*.jpg')))\n",
        "print('Number of images = ', image_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AusD_2SNfB4z",
        "outputId": "de008a5f-5471-448a-84db-f9bdbd93aaf2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of images =  3670\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "daisy = list(data_dir.glob('daisy/*'))            #633\n",
        "dandelion = list(data_dir.glob('dandelion/*'))    #898\n",
        "roses = list(data_dir.glob('roses/*'))            #641\n",
        "sunflowers = list(data_dir.glob('sunflowers/*'))  #699\n",
        "tulips = list(data_dir.glob('tulips/*'))          #799\n",
        "\n",
        "#PIL.Image.open(daisy[0])"
      ],
      "metadata": {
        "id": "BRr6ckiHfv2p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Load data"
      ],
      "metadata": {
        "id": "V0QEkm-XRcsP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#some parameters\n",
        "batch_size = 32\n",
        "img_height = 180\n",
        "img_width = 180\n",
        "\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(data_dir, validation_split=0.2, subset=\"training\", seed=123,\n",
        "                                                       image_size=(img_height, img_width), batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(data_dir, validation_split=0.2, subset=\"validation\", seed=123,\n",
        "                                                     image_size=(img_height, img_width), batch_size=batch_size)\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "# print(class_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GifekoT5iGg_",
        "outputId": "28baac27-c053-4b98-f104-0f8b9dac4218"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3670 files belonging to 5 classes.\n",
            "Using 2936 files for training.\n",
            "Found 3670 files belonging to 5 classes.\n",
            "Using 734 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize the data"
      ],
      "metadata": {
        "id": "rECAJNHXSTj_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, labels in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "    plt.title(class_names[labels[i]])\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "FH8UJRl9mtBR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAxFYB3ZnICj",
        "outputId": "6309822e-3bab-49ad-d136-090a5c58b082"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 180, 180, 3)\n",
            "(32,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Configure the dataset for performance"
      ],
      "metadata": {
        "id": "A3D1zLEWSob1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "0_fSuUkyalJ_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Data augmentation"
      ],
      "metadata": {
        "id": "sYRGduJSSsu6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_augmentation = keras.Sequential(\n",
        "  [\n",
        "    layers.RandomFlip(\"horizontal\", input_shape=(img_height, img_width,3)),\n",
        "    layers.RandomRotation(0.1),\n",
        "    layers.RandomZoom(0.1)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "TjkskO-NjEkA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for images, _ in train_ds.take(1):\n",
        "  for i in range(9):\n",
        "    augmented_images = data_augmentation(images)\n",
        "    ax = plt.subplot(3, 3, i + 1)\n",
        "    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "id": "SNOdxeC0jSlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Define Model"
      ],
      "metadata": {
        "id": "1pb_ITZ0S3iF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(class_names)\n",
        "\n",
        "model = Sequential([\n",
        "  data_augmentation,\n",
        "  layers.Rescaling(1./255),\n",
        "  layers.Conv2D(16, 3, padding='same', activation='elu'),\n",
        "  layers.Conv2D(32, 3, padding='same', activation='elu'),\n",
        "  layers.MaxPool2D(pool_size=(2, 2)),\n",
        "  layers.BatchNormalization(axis=-1),\n",
        "\n",
        "  layers.Conv2D(64, 3, padding='same', activation='elu'),\n",
        "  layers.Conv2D(128, 3, padding='same', activation='elu'),\n",
        "  layers.MaxPool2D(pool_size=(2, 2)),\n",
        "  keras.layers.BatchNormalization(axis=-1),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(512, activation='elu'),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Dense(num_classes, name=\"outputs\")\n",
        "])"
      ],
      "metadata": {
        "id": "IS52BcnEbFvb"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Compile and save model"
      ],
      "metadata": {
        "id": "Mnva1dmGS7Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "#model.summary()"
      ],
      "metadata": {
        "id": "39e3khaobUV9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=5\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx0I2ZqFbeTZ",
        "outputId": "7774ade4-56e0-49b6-95f5-12a7234e0f78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "92/92 [==============================] - 35s 148ms/step - loss: 2.0263 - accuracy: 0.4275 - val_loss: 1.6380 - val_accuracy: 0.3924\n",
            "Epoch 2/5\n",
            "92/92 [==============================] - 11s 114ms/step - loss: 1.3963 - accuracy: 0.5112 - val_loss: 1.6246 - val_accuracy: 0.3665\n",
            "Epoch 3/5\n",
            "92/92 [==============================] - 11s 115ms/step - loss: 1.2435 - accuracy: 0.5480 - val_loss: 1.2788 - val_accuracy: 0.4578\n",
            "Epoch 4/5\n",
            "92/92 [==============================] - 11s 117ms/step - loss: 1.1293 - accuracy: 0.5770 - val_loss: 1.1670 - val_accuracy: 0.5490\n",
            "Epoch 5/5\n",
            "92/92 [==============================] - 11s 118ms/step - loss: 1.0577 - accuracy: 0.6063 - val_loss: 0.9862 - val_accuracy: 0.6090\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize training results"
      ],
      "metadata": {
        "id": "uTpdj06oTImo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs_range = range(epochs)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OU8hQVk_boTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Saving and Loading"
      ],
      "metadata": {
        "id": "TAAlbujRTLJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "metadata": {
        "id": "gx2C-1qINeSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filepath = '/content/model.h5'\n",
        "model1 = tf.keras.models.load_model(\n",
        "    filepath, custom_objects=None, compile=True, options=None\n",
        "    )"
      ],
      "metadata": {
        "id": "scnw56cOONSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Predict on new data"
      ],
      "metadata": {
        "id": "sjHbGEF1TRqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sunflower_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\"\n",
        "sunflower_path = tf.keras.utils.get_file('Red_sunflower', origin=sunflower_url)\n",
        "\n",
        "img = tf.keras.utils.load_img(\n",
        "    sunflower_path, target_size=(img_height, img_width)\n",
        ")\n",
        "img_array = tf.keras.utils.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0) # Create a batch\n",
        "\n",
        "predictions = model1.predict(img_array)\n",
        "score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "print(\n",
        "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
        "    .format(class_names[np.argmax(score)], 100 * np.max(score))\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMwa8aSmk4Jy",
        "outputId": "979a37c7-9d76-43f5-9b29-40a0f9c9d0a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/example_images/592px-Red_sunflower.jpg\n",
            "117948/117948 [==============================] - 0s 3us/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "This image most likely belongs to sunflowers with a 96.17 percent confidence.\n"
          ]
        }
      ]
    }
  ]
}